{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1sqiCpTz_MhvNvr1FXuUcR1DfTPJ5SWJ3","timestamp":1708906411328},{"file_id":"1yVa8kHyZj2jORC5YAg3A_6PKt5N_4KNB","timestamp":1708904790146},{"file_id":"15ncw8X_c9Rkbtqqy50lY8KtJCA2D_gfy","timestamp":1708838954610}],"authorship_tag":"ABX9TyMOyZcwjfFFpGDiLfv0am8r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In this module, you learned the basics of deep learning and the fundamental architecture of artificial neural networks. During the examples in the lessons, you used a MNIST dataset. In this challenge, you'll work with another dataset: https://github.com/zalandoresearch/fashion-mnist. Using this dataset, do the following:\n","\n","Preprocess your data so that you can feed it into ANN models.\n","\n","Split your data into training and test sets.\n","\n","Try different ANN models and train them on your training set. You can play with the following:\n","\n","Number of layers\n","Activation functions of the layers\n","Number of neurons in the layers\n","Different batch sizes during training\n","Compare your models' training scores and interpret your results.\n","\n","Evaluate how your models perform on your test set. Compare the results of your models.\n","\n","Submit a link to your Notebook below. Good luck!"],"metadata":{"id":"dDNmG7fRC9Pj"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from tensorflow.keras.datasets import fashion_mnist\n","#keras.datasets.fashion_mnist.load_data()"],"metadata":{"id":"LyTwtHezBbwD","executionInfo":{"status":"ok","timestamp":1708907444582,"user_tz":360,"elapsed":6007,"user":{"displayName":"U S","userId":"13531373332520883304"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n","\n","input_dim = 784  # 28*28\n","output_dim = nb_classes = 10\n","batch_size = 128\n","nb_epoch = 20\n","\n","X_train = X_train.reshape(60000, input_dim)\n","X_test = X_test.reshape(10000, input_dim)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-c3ZV6olBgHg","executionInfo":{"status":"ok","timestamp":1708907509215,"user_tz":360,"elapsed":4217,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"8823a045-68df-48ee-d425-a9bd0d733bdf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 1us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 2s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","\n","Y_train = to_categorical(y_train, nb_classes)\n","Y_test = to_categorical(y_test, nb_classes)"],"metadata":{"id":"zpKGEvAJBjH1","executionInfo":{"status":"ok","timestamp":1708907602050,"user_tz":360,"elapsed":269,"user":{"displayName":"U S","userId":"13531373332520883304"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["X_train[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7WbVEZ2PBldp","executionInfo":{"status":"ok","timestamp":1708907604179,"user_tz":360,"elapsed":331,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"2755185e-44a9-4d87-dfd8-c6b9338cd443"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(784,)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(20,5))\n","\n","plt.subplot(141)\n","plt.imshow(X_train[123].reshape(28,28), cmap=\"gray\")\n","plt.title(\"Label of the image: {}\".format(y_train[123]))\n","\n","plt.subplot(142)\n","plt.imshow(X_train[124].reshape(28,28), cmap=\"gray\")\n","plt.title(\"Label of the image: {}\".format(y_train[124]))\n","\n","plt.subplot(143)\n","plt.imshow(X_train[125].reshape(28,28), cmap=\"gray\")\n","plt.title(\"Label of the image: {}\".format(y_train[125]))\n","\n","plt.subplot(144)\n","plt.imshow(X_train[126].reshape(28,28), cmap=\"gray\")\n","plt.title(\"Label of the image: {}\".format(y_train[126]))\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"0npXVXmjBnPY","executionInfo":{"status":"ok","timestamp":1708907608755,"user_tz":360,"elapsed":853,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"1ce5c90f-abbf-45de-cf9b-ccef2e5e5ac5"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x500 with 4 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAABj0AAAGTCAYAAABzttCAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT5UlEQVR4nO3deZTddX0//tdktsxkD9lNCEnYRBYrS0QEIqQBrMrihlpFbUEt+K3wUzyoyGL7RaG1HEpc6mmJ8gUrqIC1HijFBKomKItARBACkUBIyEIyySSZ9fP7g8PUIQHyCvdmZj7zeJwz55A7z/nM+3M/936e994X905NURRFAAAAAAAADHBD+noBAAAAAAAAlWDoAQAAAAAAlIKhBwAAAAAAUAqGHgAAAAAAQCkYegAAAAAAAKVg6AEAAAAAAJSCoQcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOjBq1q+fHnU1NTEP/zDP1Rsm4sWLYqamppYtGhRxbb52GOPxbx582LUqFFRU1MTN998c3obc+bMiQMPPLBia3o5H/3oR2Ovvfaq+u8B6G90SuXpFGAw0ieVp0+AwUifVJ4+oT8w9CipBQsWRE1NTdxzzz19vZTd5owzzoiHHnoo/v7v/z6uvfbaOOyww3aYW7lyZVx88cXx29/+dvcukNiyZUvMnz8/5s2bF5MnT44RI0bEn/3Zn8U3v/nN6Orq6uvlAS9Dp+iU/kinwMCjT/RJf6RPYODRJ/qkP3pxgPZyX2eeeWZfL3FQqevrBUAlbN26NRYvXhxf/OIX45xzznnF7MqVK+OSSy6JvfbaK974xjfungW+xHe+853o7u7uk9/dl5544on49Kc/Hccff3ycd955MXLkyLjtttvib/7mb2LJkiXx3e9+t6+XCKBTBgidAvR3+mRg0CdAf6dPBobx48fHtddeu93lt956a1x33XUxb968PljV4GXoQSmsWbMmIiJGjx7dtwvZSfX19X29hD4xadKkeOihh+INb3hDz2Wf+MQn4uMf/3hcc801ceGFF8bee+/dhysE0CkDhU4B+jt9MjDoE6C/0ycDw7Bhw+Iv//Ivt7t8wYIFMXLkyHjnO9/ZB6savHy81SDW3t4eX/7yl+PQQw+NUaNGxbBhw+Loo4+OhQsXvuzP/NM//VNMnz49mpqa4thjj42lS5dul3nkkUfiPe95T4wdOzaGDh0ahx12WPzkJz/Z5XXef//9cdJJJ8XIkSNj+PDhcfzxx8eSJUt6vn/xxRfH9OnTIyLic5/7XNTU1LzsZwcuWrQoDj/88IiI+NjHPtbzFrMFCxb0yj388MPxtre9LZqbm+N1r3tdXH755dttq62tLS666KLYe++9o7GxMaZNmxbnn39+tLW1veo+vfTzDf/0MyTnz58fM2fOjObm5pg3b16sWLEiiqKIr3zlKzF16tRoamqKk08+OdavX99rm7fcckv8xV/8RUyZMiUaGxtj1qxZ8ZWvfGWHb8l+8Xc0NTXFEUccEf/zP/8Tc+bMiTlz5uzSPq5duzYeeeSR2LJlyyvu97hx43o9mXjRqaeeGhERv//971/x54H+S6foFJ0CVII+0Sf6BKgEfaJPdnef7Mizzz4bCxcujNNOOy2GDh2a/nleg4JSuuaaa4qIKH7zm9+8bGbNmjXF5MmTi/POO6/45je/WVx++eXFfvvtV9TX1xf3339/T+7JJ58sIqI46KCDir322qv42te+VlxyySXF2LFji/HjxxerVq3qyS5durQYNWpUccABBxRf+9rXiquvvro45phjipqamuLHP/5xT27hwoVFRBQLFy58xf1YunRpMWzYsGLy5MnFV77yleKrX/1qMWPGjKKxsbFYsmRJURRF8cADDxT/9E//VERE8YEPfKC49tpri5tuummH21u1alVx6aWXFhFRnHXWWcW1115bXHvttcWyZcuKoiiKY489tpgyZUoxbdq04m//9m+Lb3zjG8Vxxx1XRETxs5/9rGc7XV1dxbx584rm5ubiM5/5TPHtb3+7OOecc4q6urri5JNPfsV9KoqiOOOMM4rp06dvdx2/8Y1vLA444IDi61//evGlL32paGhoKN785jcXX/jCF4q3vOUtxVVXXVX8n//zf4qampriYx/7WK9tnnLKKcX73ve+4oorrii++c1vFu9973uLiCg++9nP9sp94xvfKCKiOProo4urrrqqOO+884qxY8cWs2bNKo499thd2seLLrpop47ny/mXf/mXIiKKX/3qV7v080B16ZSbdrg9naJTgBx9ctMOt6dP9AmQo09u2uH29En/65Ovf/3rRUQUt99+e/pneW0MPUpqZwqgs7OzaGtr63XZ888/X0ycOLH4+Mc/3nPZiyenpqam4umnn+65/O677y4iojj33HN7Ljv++OOLgw46qNi2bVvPZd3d3cVb3vKWYp999um5bGcL4JRTTikaGhp6TtBFURQrV64sRowYURxzzDHbrfGKK654xe0VRVH85je/KSKiuOaaa7b73rHHHltERPG9732v57K2trZi0qRJxbvf/e6ey6699tpiyJAhxf/8z//0+vlvfetbRUQUv/zlL19xDS9XAOPHjy82bNjQc/kFF1xQRERxyCGHFB0dHT2Xf+ADHygaGhp6Xc9btmzZ7vd84hOfKJqbm3tybW1txR577FEcfvjhvba3YMGCIiJ6FUBmH19LAbS1tRUHHHBAMWPGjF5rAvoPnfLydIpOAXaePnl5+kSfADtPn7w8fdK/+uTQQw8tJk+eXHR1daV/ltfGx1sNYrW1tdHQ0BAREd3d3bF+/fro7OyMww47LO67777t8qecckq87nWv6/n3EUccEbNnz46f/exnERGxfv36+PnPfx7ve9/7YtOmTbF27dpYu3ZtrFu3Lk444YR47LHH4plnntnp9XV1dcV//dd/xSmnnBIzZ87suXzy5MnxwQ9+MH7xi19ES0vLru7+yxo+fHivz+BraGiII444Ip544omey2688cZ4/etfH/vvv3/Pfq5duzaOO+64iIhXfLvkK3nve98bo0aN6vn37NmzIyLiL//yL6Ourq7X5e3t7b2uz6ampp7/fvH6P/roo2PLli3xyCOPRETEPffcE+vWrYszzzyz1/Y+9KEPxZgxY3qtJbOPF198cRRFsd1bBXfGOeecEw8//HBcffXVvdYEDCw6Zcd0Sn4fdQoMbvpkx/RJfh/1CQxu+mTH9El+H3e1T/7whz/EvffeG6effnoMGeIl+N1New9y3/3ud+Mf//Ef45FHHomOjo6ey2fMmLFddp999tnusn333TduuOGGiIh4/PHHoyiKuPDCC+PCCy/c4e977rnnepXIK1mzZk1s2bIl9ttvv+2+9/rXvz66u7tjxYoVO/z81ddi6tSpUVNT0+uyMWPGxIMPPtjz78ceeyx+//vfx/jx43e4jeeee26Xfveee+7Z698vlsG0adN2ePnzzz/fc9nvfve7+NKXvhQ///nPtyvGjRs3RkTEH//4x4iI7f4QX11d3XafCVmtffxTV1xxRXznO9+Jr3zlK/H2t7/9NW8P6Fs6ZXs65QU6BcjQJ9vTJy/QJ0CGPtmePnnB7uiT6667LiJeGLqw+xl6DGL/7//9v/joRz8ap5xySnzuc5+LCRMmRG1tbVx22WWxbNmy9Pa6u7sjIuKzn/1snHDCCTvMvPTE0x/V1tbu8PKiKHr+u7u7Ow466KD4+te/vsPsS0/Yr/V3v9qaNmzYEMcee2yMHDkyLr300pg1a1YMHTo07rvvvvj85z/fc2wyqrWPL1qwYEF8/vOfj09+8pPxpS996TVtC+h7OmXHdMoLdAqws/TJjumTF+gTYGfpkx3TJy+odp9ERFx//fWx3377xaGHHvqat0Weoccg9sMf/jBmzpwZP/7xj3tNeS+66KId5h977LHtLvvDH/7QMy198e149fX1MXfu3Ne8vvHjx0dzc3M8+uij233vkUceiSFDhuzSSeilE+1dMWvWrHjggQfi+OOPr8j2XqtFixbFunXr4sc//nEcc8wxPZc/+eSTvXLTp0+PiBf+D4W3ve1tPZd3dnbG8uXL4+CDD+65rJr7eMstt8Rf//Vfx2mnnRbz58+v6LaBvqFTdp1OeW10CpSLPtl1+uS10SdQLvpk1+mT1+7uu++Oxx9/PC699NKKb5ud4wPFBrEXJ6l/Os29++67Y/HixTvM33zzzb0+T+/Xv/513H333XHSSSdFRMSECRNizpw58e1vfzueffbZ7X5+zZo16fXNmzcvbrnllli+fHnP5atXr47rr78+3vrWt8bIkSNT24yIGDZsWES8MCneVe973/vimWeeie985zvbfW/r1q3R2tq6y9veFTs6lu3t7fGNb3yjV+6www6LPfbYI77zne9EZ2dnz+XXXXddr7cNRuT2ce3atfHII4/Eli1bXnWtd911V5x++ulxzDHHxHXXXedzDaEkdMqG9M++SKfoFOB/6ZMN6Z99kT7RJ8D/0icb0j/7In2y633youuvvz4iIj74wQ/u9M9QWd7pUXL/9m//Frfeeut2l//t3/5tvOMd74gf//jHceqpp8Zf/MVfxJNPPhnf+ta34oADDojNmzdv9zN77713vPWtb41PfepT0dbWFldeeWXssccecf755/dk5s+fH29961vjoIMOijPPPDNmzpwZq1evjsWLF8fTTz8dDzzwQGr9f/d3fxe33357vPWtb42/+Zu/ibq6uvj2t78dbW1tcfnll+evkHhhmjt69Oj41re+FSNGjIhhw4bF7Nmzd/iZji/nwx/+cNxwww3xyU9+MhYuXBhHHXVUdHV1xSOPPBI33HBD3HbbbXHYYYft0vp2xVve8pYYM2ZMnHHGGfF//s//iZqamrj22mt7FULEC3+g6uKLL45Pf/rTcdxxx8X73ve+WL58eSxYsCBmzZrVa7qd2cerr746Lrnkkli4cOEr/mGnP/7xj/Gud70rampq4j3veU/ceOONvb5/8MEH95q8A/2LTtmeTtEpQJ4+2Z4+0SdAnj7Znj7puz55UVdXV/zgBz+IN7/5zTFr1qyKXhckFJTSNddcU0TEy36tWLGi6O7uLv7v//2/xfTp04vGxsbiz/7sz4qf/vSnxRlnnFFMnz69Z1tPPvlkERHFFVdcUfzjP/5jMW3atKKxsbE4+uijiwceeGC7371s2bLiIx/5SDFp0qSivr6+eN3rXle84x3vKH74wx/2ZBYuXFhERLFw4cJX3Zf77ruvOOGEE4rhw4cXzc3Nxdve9rbiV7/6Va/Mn65xZ9xyyy3FAQccUNTV1RURUVxzzTVFURTFscceW7zhDW/YLv/S66QoiqK9vb342te+VrzhDW8oGhsbizFjxhSHHnpocckllxQbN258xd//Stfxn3rxerrxxht7Xf7i8f3Nb37Tc9kvf/nL4s1vfnPR1NRUTJkypTj//POL2267bYfX81VXXdVz3I844ojil7/8ZXHooYcWJ5544i7t40UXXbRTx/PF/Xm5r4suuugVfx7oGzrllekUnQLsHH3yyvSJPgF2jj55Zfqkb/rkRbfeemsREcVVV121U3mqo6YoXjIWAwad7u7uGD9+fJx22mk7fGsfAOwsnQJAJegTACpBnwxOPqgSBplt27Zt9xbA733ve7F+/fqdepseALxIpwBQCfoEgErQJ7zIOz1gkFm0aFGce+658d73vjf22GOPuO++++Jf//Vf4/Wvf33ce++90dDQ0NdLBGCA0CkAVII+AaAS9Akv8ofMYZDZa6+9Ytq0aXHVVVfF+vXrY+zYsfGRj3wkvvrVrzr5A5CiUwCoBH0CQCXoE17knR4AAAAAAEAp+JseAAAAAABAKRh6AAAAAAAApdDv/qZHd3d3rFy5MkaMGBE1NTV9vRyAAaUoiti0aVNMmTIlhgwx19YpALtOp/wvfQKw6/TJ/9InALsu0yf9buixcuXKmDZtWl8vA2BAW7FiRUydOrWvl9HndArAa6dT9AlAJegTfQJQCTvTJ/1u6DFixIi+XgJJo0ePTuXHjRuXyn/oQx9K5VetWpXKP/zww6n8rpg8eXIqP2fOnFR+0aJFqfwNN9yQyjPwOJe+YDBeD7W1tal8V1dXlVayezzwwAOp/B133JHK//SnP03ln3322VS+ri7/UCz7RPmoo45K5T/+8Y+n8tmOY+AZjOfSl3Id9L3hw4en8tlzZfZ8vHz58lR+06ZNqXwZHHjggal8fX19Kr9u3bpU/qmnnkrlqTznUtcBQCXszLm0akOP+fPnxxVXXBGrVq2KQw45JP75n/85jjjiiFf9OW/vG3iyxyz7gtzQoUNT+cbGxlR+V15wympoaEjlm5qaqrr97DEriiKVp++V6Vy6q30SsXuuh2r/juz9r0zHfmdknzhmz6/Zjsh2XDYfkX9RKNujI0eOTOUHm8HYoWU5r/T3PuGVVfs5RzbvNvHqqn0Msh+T1N/O3/1tPbtDme43XvMC6Ds7cy6tyocp/uAHP4jzzjsvLrroorjvvvvikEMOiRNOOCGee+65avw6AEpKnwBQCfoEgErRKQD9X1WGHl//+tfjzDPPjI997GNxwAEHxLe+9a1obm6Of/u3f6vGrwOgpPQJAJWgTwCoFJ0C0P9VfOjR3t4e9957b8ydO/d/f8mQITF37txYvHjxdvm2trZoaWnp9QUA2T6J0CkAbE+fAFApXvMCGBgqPvRYu3ZtdHV1xcSJE3tdPnHixB3+genLLrssRo0a1fOV/YNzAJRTtk8idAoA29MnAFSK17wABoaqfLxVxgUXXBAbN27s+VqxYkVfLwmAAUqnAFAJ+gSAStAnAH2jrtIbHDduXNTW1sbq1at7Xb569eqYNGnSdvnGxsZobGys9DIAGOCyfRKhUwDYnj4BoFK85gUwMFT8nR4NDQ1x6KGHxh133NFzWXd3d9xxxx1x5JFHVvrXAVBS+gSAStAnAFSKTgEYGCr+To+IiPPOOy/OOOOMOOyww+KII46IK6+8MlpbW+NjH/tYNX4dACWlTwCoBH0CQKXoFID+rypDj/e///2xZs2a+PKXvxyrVq2KN77xjXHrrbdu94eeAOCV6BMAKkGfAFApOgWg/6spiqLo60X8qZaWlhg1alRfL6NfGzNmTCr/pje9KZWfPHlyKl9TU5PKP//886n88OHDU/nTTjstlZ8wYUIqv2nTplQ+ItK36XvvvTeV/8lPfpLKjx07NpUfOnRoKv/HP/4xlb///vtT+dbW1lR+MNq4cWOMHDmyr5fR58rQKdlzbLVrPXv++PCHP5zKv+c970nlx40bl8pnO2Xq1KmpfH/00s+cfjVdXV2p/M0335zKZzvrtttuS+Wrrb/dJ3cHnaJPdsaIESNS+WOOOSaVb2pqSuWzzzk2b96cymdt2LAhlc8+J7v++utT+YiIT3/606l8Z2dnKt/S0lLVfPZ5XPbvKixfvjyV/+1vf5vKD0b6pBx9AtDXdqZPKv43PQAAAAAAAPqCoQcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOgBAAAAAACUgqEHAAAAAABQCoYeAAAAAABAKRh6AAAAAAAApWDoAQAAAAAAlIKhBwAAAAAAUAqGHgAAAAAAQCnUFEVR9PUi/lRLS0uMGjWqr5exW40bNy6VP/XUU1P59evXp/ItLS2pfGtrayrf2NiYym/cuDGVf+6551L5urq6VL6hoSGVj8hfp93d3an8pEmTUvnsPmTz2dt09j5/0003pfKbN29O5ctg48aNMXLkyL5eRp/rj51SW1ubynd1daXy++23Xyp/9dVXp/JTp05N5YcNG5bKd3R0pPLt7e2pfGdnZyqfXU/2+Ga3H5G/TTQ3N6fy2Z7OHuOsDRs2pPL33ntvKv+Rj3wklc8aMiT3/xhlHwPsDjqlf/ZJtdXU1KTyJ554Yir/zDPPpPLZx3PZ5yjZc2s2n+2r7NP0XbmPrl27NpXPnp+yfZJ9DpF9jpK9TWefY23dujWVz/ZVdv397KWeiNAnEYOzTwAqbWf6xDs9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAohZqiKIq+XsSfamlpiVGjRvX1MnarU089tarbX7lyZSrf3NycymdvQt3d3al8bW1tKp9dz7Zt21L5zs7OVD4ivw/19fWpfEdHRyqflb1O29vbU/nhw4en8lm/+MUvqrr9/mjjxo0xcuTIvl5Gn9sdnTJkSO7/H8ieA7PuuuuuVH7PPfdM5Tds2JDKZ6+fhoaGVD57fs3Knl+7urpS+ez+7orsMcjms72YvQ9k81OmTEnlb7vttlT+9NNPT+XLQKcMzucoM2fOTOWnT5+eyi9cuDCV729GjBiRytfU1KTyLS0tqTyVl31efNBBB6XyS5cuTeVbW1tT+f5InwzOPgGotJ3pE+/0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAoBUMPAAAAAACgFOr6egFl1NzcnMqPGzculV+5cmUqP3z48FS+ra0tla+trU3l6+vrU/murq5UviiKquY7OztT+YiIDRs2pPJ1dbm7ZvYYDxmSm3d2d3en8tn1d3R0pPITJkxI5RsaGlL59vb2VJ7Brdr3pw9/+MOp/NSpU1P5devWpfJNTU2pfE1NTSqf1djYmMpn1589v2bXk+24iHzvbtq0KZVfv359Kp+9D2RvE9ntZ2/TU6ZMSeWrLXv9ZB/HwM6aNGlSKn///fen8nvuuWcq/8Mf/jCV32effVL50aNHp/KDUfZ8s3bt2lQ+2z/Lly9P5X/wgx+k8tdcc00qv2rVqlR+/PjxqXxra2sqDwCDmXd6AAAAAAAApWDoAQAAAAAAlIKhBwAAAAAAUAqGHgAAAAAAQCkYegAAAAAAAKVg6AEAAAAAAJSCoQcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOgBAAAAAACUgqEHAAAAAABQCnV9vYAymjBhQio/ZsyYVH7z5s2pfGtraypfX1+fymd1dXWl8p2dnan8li1bUvnVq1en8tOmTUvlIyIOP/zwVP6//uu/UvnsdTR8+PBUvqGhIZVvb29P5UePHp3KZ9eTvY9lbxMMbtn7X9bBBx+cymfP4dl8URSpfPb+PXbs2FQ+e7556KGHUvn169en8j/60Y9S+aOPPjqVj4hYvnx5Kn/88cen8rNnz07ls7ehtra2VP6pp55K5avdEdkOzT5uq6mpSeWz90nYWdn70oYNG1L5Bx54IJWfMmVKKp89f69ZsyaVz973svnsuWDIkPz/z5hdU/Z31NXlXm7IPo+eOHFiKj9v3rxUft99903lL7jgglT+sMMOS+Wz/Q8Ag5l3egAAAAAAAKVQ8aHHxRdfHDU1Nb2+9t9//0r/GgBKTp8AUCk6BYBK0CcAA0NVPt7qDW94Q/z3f//3//6S5NtaASBCnwBQOToFgErQJwD9X1XOzHV1dTFp0qRqbBqAQUSfAFApOgWAStAnAP1fVf6mx2OPPRZTpkyJmTNnxoc+9KH0H6AEgAh9AkDl6BQAKkGfAPR/FX+nx+zZs2PBggWx3377xbPPPhuXXHJJHH300bF06dIYMWLEdvm2trZoa2vr+XdLS0ullwTAAJTtkwidAsCOeY4CQCXoE4CBoeJDj5NOOqnnvw8++OCYPXt2TJ8+PW644Yb4q7/6q+3yl112WVxyySWVXgYAA1y2TyJ0CgA75jkKAJWgTwAGhqp8vNWfGj16dOy7777x+OOP7/D7F1xwQWzcuLHna8WKFdVeEgAD0Kv1SYROAWDneI4CQCXoE4D+qepDj82bN8eyZcti8uTJO/x+Y2NjjBw5stcXALzUq/VJhE4BYOd4jgJAJegTgP6p4kOPz372s3HnnXfG8uXL41e/+lWceuqpUVtbGx/4wAcq/asAKDF9AkCl6BQAKkGfAAwMFf+bHk8//XR84AMfiHXr1sX48ePjrW99ayxZsiTGjx9f6V8FQInpEwAqRacAUAn6BGBgqCmKoujrRfyplpaWGDVqVF8v4zU57LDDUvm99947ld9zzz1T+d/85jepfGNjYyrf1taWyre2tqby69evT+Wbm5tT+S1btqTyf/3Xf53KR0Scf/75qfwvf/nLVP7cc89N5Tds2JDKjx49OpXPestb3pLKP/jgg6n82rVrU/mlS5em8v3Rxo0bvXU6ytEpN954Yyo/e/bsVD57DpwxY0Yqv27dulT+O9/5Tiq/bdu2VP7pp59O5W+//fZU/v3vf38q397enspHRKxZsyaVz94mFi1alMofe+yxqfwb3/jGVP7P//zPU/nly5en8tmHwnPmzEnln3rqqVS+P9Ip5eiTrNra2lQ++xi8paUllX/iiSdS+fr6+lQ+u781NTWpfLWfdmfXE5FfU3d3d1W339XVVdV8U1NTKp89740YMSKVr/bz1v5InwzOPgGotJ3pk6r/TQ8AAAAAAIDdwdADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAU6vp6AWU0bty4VH7jxo2p/LZt21L5sWPHpvKtra2pfNaWLVtS+VNOOSWVv+iii1L5p556KpUfPnx4Kh8R8eUvfzmVf9e73pXKZ/f5nHPOSeW3bt2ayu+5556p/KZNm1L57H2gubk5lYf+pNq336IoUvkFCxak8l//+tdT+RkzZqTyCxcuTOWPO+64VH7ixImp/N57753KP//886l8RL7Xs+fMZcuWpfJdXV2p/Jo1a1L53/3ud6n8Bz7wgVQ+e/3U19en8tBfjBw5MpW/4YYbUvklS5ak8lm1tbWpfLbfampqUvkhQ3L//2B2PVnZ9UdEdHd3p/J1dbmXD7L7nD3GbW1tqXz2/L0rz/sy5s6dm8r/5Cc/qdJKAKB8vNMDAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSqOvrBZTRiBEjUvm2trZUftOmTan8xo0bU/khQ3KzsPb29lT+He94Ryr/93//96n8z372s1Q+u56TTz45lY+IeOc735nKn3XWWan8r3/961R+2rRpqfxzzz2Xymdvo9n88OHDU/nNmzen8tCfjBkzJpWvr69P5RsbG1P5T3ziE6l81vnnn5/Kf/rTn07l99lnn1S+qakple/s7Ezla2trU/mIfK9nz5lz585N5f/hH/4hlX/kkUdS+fnz56fyp556aiqfvQ9k75PQX7S0tKTyJ5xwQir/pje9KZVfs2ZNKt/d3Z3Kd3V1pfLZ83d2+9nnWLvSD1lFUaTy2WOQ3X5NTU0qX+31rFy5MpXP3qbHjRuXymevH6Aysve9ap/7stvP+ou/+Iv0z/znf/5nFVbyv/rbdZQ10Nc/UHmnBwAAAAAAUAqGHgAAAAAAQCkYegAAAAAAAKVg6AEAAAAAAJSCoQcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOgBAAAAAACUgqEHAAAAAABQCoYeAAAAAABAKRh6AAAAAAAApVDX1wsgorW1NZU/6qijUvn29vZUftmyZal8bW1tKv+xj30slf/BD36Qyj/++OOp/J133pnKL168OJWPiCiKIpX/1Kc+lco/++yzqXxjY2Mqn5Xd3zFjxqTyGzZsSOWrvb9QTdn7R/acP3To0FT+/vvvT+X/8R//MZX/+Mc/nspnPf3006n81q1bU/ns+SZ7PouImDBhQiqfPSe/+c1vTuV/+MMfpvLvete7UvkrrrgilR85cmQq39bWlsqPHz8+lYf+YubMman8U089lcp3dnam8tn76ujRo1P5bH8y8GQ7NNvpzc3NqXx3d3cqn33MBvSN7GPpam+/oaEhlf+Hf/iHVP7tb397Kh8Rceihh6byl156aSpf7WOQVVNT09dLeE2yxyv7fGnp0qWpfLV4pwcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOgBAAAAAACUgqEHAAAAAABQCoYeAAAAAABAKRh6AAAAAAAApWDoAQAAAAAAlIKhBwAAAAAAUAqGHgAAAAAAQCkYegAAAAAAAKVQ19cLKKPOzs5UvrW1NZVvaWlJ5SdNmpTKL126NJWfMmVKKr/vvvum8hdddFEqP23atFT+gQceSOUvvvjiVD4i4rbbbkvlp06dmsoPGZKbX27YsCGVr6mpSeWzGhsbU/na2tpUvr6+PpWH/iR7fx0+fHgqv2XLllQ+e4699tprU/mPf/zjqfy6detS+WHDhqXy69evT+Wznbsr59eZM2em8suWLUvls52SfRzz3e9+N5XPdkT2mDU1NaXy2WMM/cWhhx6aymfPl9lzwcqVK1P5zZs3p/LZfrj77rtT+VWrVqXyzzzzTCq/du3aVD7b5xERY8eOTeUnT56cymef9+2///6p/Lve9a5UfujQoal89jbX3d2dym/atCmVz/ZhW1tbKg+DRfbxd1EUVVrJCw488MBU/s4770zls334u9/9LpWPiDj88MNT+RtvvDGVf+9735vKV1u1bxNZX/nKV1L5j3zkI6l89nXuk08+OZXPvg69s7zTAwAAAAAAKIX00OOuu+6Kd77znTFlypSoqamJm2++udf3i6KIL3/5yzF58uRoamqKuXPnxmOPPVap9QJQEvoEgErQJwBUik4BKIf00KO1tTUOOeSQmD9//g6/f/nll8dVV10V3/rWt+Luu++OYcOGxQknnBDbtm17zYsFoDz0CQCVoE8AqBSdAlAO6b/pcdJJJ8VJJ520w+8VRRFXXnllfOlLX+r5/K7vfe97MXHixLj55pvj9NNPf22rBaA09AkAlaBPAKgUnQJQDhX9mx5PPvlkrFq1KubOndtz2ahRo2L27NmxePHiSv4qAEpMnwBQCfoEgErRKQADR/qdHq9k1apVERExceLEXpdPnDix53sv1dbWFm1tbT3/bmlpqeSSABiAdqVPInQKAL3pEwAqxWteAANHRd/psSsuu+yyGDVqVM/XtGnT+npJAAxQOgWAStAnAFSCPgHoGxUdekyaNCkiIlavXt3r8tWrV/d876UuuOCC2LhxY8/XihUrKrkkAAagXemTCJ0CQG/6BIBK8ZoXwMBR0aHHjBkzYtKkSXHHHXf0XNbS0hJ33313HHnkkTv8mcbGxhg5cmSvLwAGt13pkwidAkBv+gSASvGaF8DAkf6bHps3b47HH3+8599PPvlk/Pa3v42xY8fGnnvuGZ/5zGfi7/7u72KfffaJGTNmxIUXXhhTpkyJU045pZLrBmCA0ycAVII+AaBSdApAOaSHHvfcc0+87W1v6/n3eeedFxERZ5xxRixYsCDOP//8aG1tjbPOOis2bNgQb33rW+PWW2+NoUOHVm7VAAx4+gSAStAnAFSKTgEoh/TQY86cOVEUxct+v6amJi699NK49NJLX9PCBrIhQ3KfGtbY2JjKr1+/PpXv6upK5WtqalL5jo6OVD7rq1/9aiq/1157pfIPPfRQKj98+PBUPiJ/DNrb21P57OeCPv/886l89jadfcBXW1ubynd2dqbyY8aMSeXZPQZrn2Rv79n7U3d3dyqfXc9zzz2Xyo8YMSKVz2pqakrls+f85cuXp/L77rtvKv+5z30ulY+ImD9/fipfX1+fyr/xjW9M5W+88cZUfuvWran8tm3bUvlsZ2Xz48ePT+WpvsHaJ1nZx7AtLS2p/MSJE1P5zZs3p/JHHXVUKg8vNWvWrFT+9ttvT+Wz94FsP7/lLW9J5RcuXJjK8wKdUnnZ15iyXul4VSKf9eEPfziV/973vpfKL126NJV/5plnUvm1a9em8hH51+GyzzdWrlyZyn/xi19M5a+55ppUPiv7GOzKK69M5Q855JBU/qmnnkrlR48encrPnDkzlc/epndWRf+mBwAAAAAAQF8x9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKIW6vl5AGdXW1qbyQ4cOTeU3b96cytfV5Q5zdj1r165N5bds2ZLKP/TQQ6n8t7/97VR+2rRpqXx2PRERH/rQh1L5jRs3pvJnn312Kt/U1JTKd3V1pfKjR49O5YcNG5bKjxs3LpWH/qS5uTmVz57Di6Koaj57/siezz71qU+l8mvWrEnl77vvvlT+kEMOSeWXLl2aym/atCmVj4g466yzUvnsMXv44YdT+S996UupfPacv3Xr1lQ+21lZY8eOrer2oVquueaaVP573/teKr/ffvul8g0NDan88OHDU/lJkyal8tk+7OjoSOU7Ozurms+uPyKipqYm/TMZ2fNxdh+6u7tT+WXLlqXyixcvTuX33XffVD77GGndunWpPOUxZEju/1felfNBNbdf7fVkvelNb0rlL7jgglT+Pe95Typ/5513pvK/+c1vUvkDDzwwlR8/fnwqHxExatSoVP7ZZ59N5UeMGJHK/9u//VsqP3/+/FQ++xwue522tbWl8tnbRPYxRrZvjzvuuFT+Jz/5SSq/s7zTAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUqjr6wWUUVtbWyo/cuTIVL4oilR+69atqXxTU1Mqv23btlT+a1/7Wip/+umnp/LHHntsKp89Xj/72c9S+YiIhx56KJX/93//91R+9erVqfz48eNT+VWrVlV1+9nbXENDQyr/yCOPpPLNzc2p/JYtW1J5BrfGxsZUvr6+PpXPdsSQIdX9/x+y59hZs2al8occckgq//a3vz2Vz3rnO9+Zynd1daV/R21tbSqfvU285z3vSeWz1qxZk8p3d3en8tnbdPb62WOPPVJ56C/22muvVH7t2rWp/MMPP5zKZ02cODGVr6vLPdVtbW1N5dvb21P5zs7OVD577tsdsmuqqalJ5bOdmH0enX1M8qEPfSiVh2rpj+eDasr21T//8z+n8u94xztS+SeffDKVv/rqq1P57OshRx99dCqfXc+8efNS+YiIqVOnpvLZzs36xS9+kcpnH2Nk/e53v0vlOzo6Uvnsa2TZfs4+X5o2bVoqXy3e6QEAAAAAAJSCoQcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOgBAAAAAACUgqEHAAAAAABQCoYeAAAAAABAKRh6AAAAAAAApWDoAQAAAAAAlIKhBwAAAAAAUAqGHgAAAAAAQCnU9fUCBoK6utzV1N3dXdXtjxo1KpVfuXJlKp81ZsyYVP4nP/lJKt/R0ZHKn3zyyan87NmzU/lf//rXqXxExPe+971Ufvz48an8HnvskcoPGZKbdzY2NqbyTzzxRCp/wAEHpPLZ9be1taXy2f3dsmVLKs/glr191dfXp/JFUaTyNTU1qXy1bdiwIZV//vnnU/ns9Znt9Gw+u56IiM7OzlS+trY2le/q6krls7eh7H0gu/7s44asbOdCfzFs2LBUPvv4Kbv9rVu3pvLDhw9P5avdh9nzfXb71V7P7pA9BtV+3p29TqdMmZLKjx07NpXfvHlzKt/S0pLKr1+/PpWnPJqamlL5WbNmpfKHHXZYKn/KKaek8u9617tS+fvvvz+Vv/DCC1P5iRMnpvLZ66faz0+yj13333//VD4i/3i9oaEhlc/2Q/Z8v3HjxlT+ueeeS+Xb29tT+aFDh6by2cdU2cds2eN70EEHpfLV4p0eAAAAAABAKRh6AAAAAAAApWDoAQAAAAAAlIKhBwAAAAAAUAqGHgAAAAAAQCkYegAAAAAAAKVg6AEAAAAAAJSCoQcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOgBAAAAAACUgqEHAAAAAABQCnV9vYCBYMyYMVXd/vPPP5/K77vvvqn8mjVrUvmsxsbGVH7o0KGp/E033ZTKL1myJJWfNWtWKr8rJk+enMqPHj06le/o6EjlhwzJzTu7urpS+T322COVHzFiRCq/cuXKVD6rvr6+qttncBs+fHgqn72/FkWRytfW1lZ1+1nZ+19NTU2VVvKChoaGqm6/s7Mz/TPNzc2pfPY66u7uTuWz+5C9DWXXk5XtuGo/LoRqyd7Ws/fV7LmgtbU1lZ80aVIqn5U937e1taXy1X78vSvnymqfj7P9k81nH8Nkn7du2LAhlZ8wYUIqn70+s+unf6uvr9/p2/yNN96Y2nb2+XL28ffYsWNT+ex99V/+5V9S+b333juVnzNnTir/H//xH6n8xIkTU/l99tknlV+7dm0q/4lPfCKV37x5cyofEdHS0pLKZ18XzPZDtnOzr6llnw+87nWvS+VHjhyZymfXv379+lQ+e075zW9+k8pXS/qdHnfddVe8853vjClTpkRNTU3cfPPNvb7/0Y9+NGpqanp9nXjiiZVaLwAloU8AqAR9AkCl6BSAckgPPVpbW+OQQw6J+fPnv2zmxBNPjGeffbbn6/vf//5rWiQA5aNPAKgEfQJApegUgHJIf7zVSSedFCeddNIrZhobG6v+9mMABjZ9AkAl6BMAKkWnAJRDVf6Q+aJFi2LChAmx3377xac+9alYt25dNX4NACWnTwCoBH0CQKXoFID+r+J/yPzEE0+M0047LWbMmBHLli2LL3zhC3HSSSfF4sWLd/jHi9ra2nr9EbjsH78BoJyyfRKhUwDYnj4BoFK85gUwMFR86HH66af3/PdBBx0UBx98cMyaNSsWLVoUxx9//Hb5yy67LC655JJKLwOAAS7bJxE6BYDt6RMAKsVrXgADQ1U+3upPzZw5M8aNGxePP/74Dr9/wQUXxMaNG3u+VqxYUe0lATAAvVqfROgUAF6dPgGgUrzmBdA/VfydHi/19NNPx7p162Ly5Mk7/H5jY2M0NjZWexkADHCv1icROgWAV6dPAKgUr3kB9E/pocfmzZt7TbCffPLJ+O1vfxtjx46NsWPHxiWXXBLvfve7Y9KkSbFs2bI4//zzY++9944TTjihogsHYGDTJwBUgj4BoFJ0CkA5pIce99xzT7ztbW/r+fd5550XERFnnHFGfPOb34wHH3wwvvvd78aGDRtiypQpMW/evPjKV75isg1AL/oEgErQJwBUik4BKIf00GPOnDlRFMXLfv+22257TQsCYHDQJwBUgj4BoFJ0CkA5VP1vepRBtSf2W7ZsSeU7OztT+SlTpqTyTz31VCpfW1ubyo8cOTKVr6vL3Uyff/75VP6ee+5J5YcPH57KR0QMHTo0/TMZ9fX1qXz2NtTe3p7K77nnnqn8iBEjUvk1a9ak8g0NDan8kCFDUnnIaGpqSuVrampS+Vd6klYJ2fVUe/vVvr9mr89sPtuhERHd3d2pfLVvQ9l96OrqSuWzjwOy68nu77hx41J56C+y96XsuSP7eCu7/ezj0eXLl6fy8FLZ53DZ+0D2Nk25HHfccTv9PH7ChAmpbWdvi1nZ5+PLli1L5bP3vez5ftSoUan83nvvncr//ve/T+Wzjy1f6W+S7ci6detS+V2RfY6btXnz5lQ++7rjpk2bUvl99tknlb/66qtT+VtuuSWVzz7Ge+KJJ1L57Gt806dPT+WrxSt7AAAAAABAKRh6AAAAAAAApWDoAQAAAAAAlIKhBwAAAAAAUAqGHgAAAAAAQCkYegAAAAAAAKVg6AEAAAAAAJSCoQcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOgBAAAAAACUQl1fL2AgKIqiqvn29vZUvrOzM5VvbGys6va7urpS+ez1U19fn8qPGzculc/K7m9Efp9rampS+e7u7qpuPyu7/W3btqXyW7duTeWHDx+eykM11dXlqre2tjaVz55vBrrs+W/IkP71/3vsyvGq9jk8K7sP2WOQ3X72PgODxbp161L5tWvXpvLZ83H2vv0///M/qfyDDz6Yyq9atSqVz55rqn1uyj7ni8g/Jsnms8/jss8JRowYkco/9NBDqfy5556byo8ePTqVX7lyZSo/2B7jld2mTZt2+j61efPm1Lazj7Wam5tT+T322COV32+//VL51tbWVH758uWpfPZ8P2vWrFT+DW94Qypf7XPxlClTUvmGhoZUPiJi2LBhqXy2H7Jryt6Gsq8ZZW9z3/3ud1P57Pk+e/3PnDkzlZ8wYUIqP3HixFQ+c3yLooiOjo6dyvavZ/4AAAAAAAC7yNADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAU6vp6AQNBbW1tKt/R0ZHKF0WRyme1tLSk8p2dnal8XV3uZpTdflZ2+zU1Nal89vYQkb9NZPO7sqaM+vr6VH7dunVVWskL+uMxhp3l9tW3uru7U3nHq/Ky5+RsPmvIkNz/A5R93JOVXU/2Ns3glb1tZR+Pvu51r0vln3nmmVR+6tSpqfzo0aNT+ex9qdrnsmo/R9yV39HfrqOGhoZU/tBDD03lzz333FT+iSeeSOWffvrpVJ5y+dWvfrXT2QsvvDC17dNPPz2VHzNmTCo/YsSIVD7bJ83Nzan8/vvvn8pn9zd7rmlra0vln3/++VR+zZo1qXx2PStWrEjlIyKee+65VD77GKC1tTWVr/Z1lO3PI444IpUfNmxYKt/e3p7KZ+9j2dfgZs6cmcpnrp/Ozs5YsmTJTmW90wMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFKo6+sFDAR1dbmrqaurq6r5IUNys6oNGzak8rW1tal8d3d3Kt/fZPd3dyiKIpWvqamp6vaHDh2aym/evDmVHz16dCqflb2N1tfXV2kl0P9U+3yTvf9lOy6r2tvfHbLHrNrHOCu7nuzjpIcffjiVnz17dirf3NycykN/cd1116Xyxx57bJVW8oLsuSb7+DL7HKizszOVz56bsue+rOxz1ojq73N2TdnH4NlO35XrKOPWW29N5RcuXJjK/+hHP0rls+uh/1qyZElV89nn+3Pnzk3ls8/3991331T+6aefTuX32GOPVH79+vWpfPbc1Nramspnj1dHR0cqP2zYsFQ+It8PI0aMSOUbGhpS+b322iuVz74umO3PkSNHpvJbtmxJ5SdPnpzKP/XUU6n8lClTUvnsY7A//vGPO53NvL4w8J/5AwAAAAAAhKEHAAAAAABQEoYeAAAAAABAKRh6AAAAAAAApWDoAQAAAAAAlIKhBwAAAAAAUAqGHgAAAAAAQCkYegAAAAAAAKVg6AEAAAAAAJSCoQcAAAAAAFAKhh4AAAAAAEAp1PX1AgaC7u7uVL6rqyuVr6vLHYYtW7ak8s8880wqX19fn8pnr5+iKFL5mpqaVD5ryJDc7C+7vxH5fcjms7e57PabmppS+ZUrV6by48aNS+UbGhpS+ewxq62tTeUhI3sOzJ6jstsfNmxYKt/e3p7Kb9u2LZXPduKunJMHm+x1lL3NZTslu/3sbeLhhx9O5d/85jen8qtXr07ls7L3YdhZmzZtSuXXrVuXymfv21kdHR2pfHNzcyqffY7V2NiYylf7vr0r139nZ2cVVvK/ss8rs7LHIPuYJ2vWrFlVzWf79tZbb03lGbyyj9d/+tOfVmklu2bkyJGp/P7775/KZ/th5syZqfz69etT+ey5r7W1NZXflddDsr8juw8bNmxI5bPny9GjR6fy2fUMHTo0lX/iiSdS+TFjxqTyf/zjH1P5gco7PQAAAAAAgFJIDT0uu+yyOPzww2PEiBExYcKEOOWUU+LRRx/tldm2bVucffbZsccee8Tw4cPj3e9+d9X/jzgABhZ9AkCl6BQAKkGfAJRHauhx5513xtlnnx1LliyJ22+/PTo6OmLevHm93sZ07rnnxn/8x3/EjTfeGHfeeWesXLkyTjvttIovHICBS58AUCk6BYBK0CcA5ZH6kOSXfibkggULYsKECXHvvffGMcccExs3box//dd/jeuvvz6OO+64iIi45ppr4vWvf30sWbIk/ZnJAJSTPgGgUnQKAJWgTwDK4zX9TY+NGzdGRMTYsWMjIuLee++Njo6OmDt3bk9m//33jz333DMWL168w220tbVFS0tLry8ABpdK9EmETgHAcxQAKkOfAAxcuzz06O7ujs985jNx1FFHxYEHHhgREatWrYqGhobt/ur9xIkTY9WqVTvczmWXXRajRo3q+Zo2bdquLgmAAahSfRKhUwAGO89RAKgEfQIwsO3y0OPss8+OpUuXxr//+7+/pgVccMEFsXHjxp6vFStWvKbtATCwVKpPInQKwGDnOQoAlaBPAAa21N/0eNE555wTP/3pT+Ouu+6KqVOn9lw+adKkaG9vjw0bNvSafK9evTomTZq0w201NjZGY2PjriwDgAGukn0SoVMABjPPUQCoBH0CMPCl3ulRFEWcc845cdNNN8XPf/7zmDFjRq/vH3rooVFfXx933HFHz2WPPvpoPPXUU3HkkUdWZsUADHj6BIBK0SkAVII+ASiP1Ds9zj777Lj++uvjlltuiREjRvR8ZuGoUaOiqakpRo0aFX/1V38V5513XowdOzZGjhwZn/70p+PII4+MN7/5zVXZAQAGHn0CQKXoFAAqQZ8AlEdq6PHNb34zIiLmzJnT6/JrrrkmPvrRj0ZExD/90z/FkCFD4t3vfne0tbXFCSecEN/4xjcqslgAykGfAFApOgWAStAnAOWRGnoURfGqmaFDh8b8+fNj/vz5u7yogW5nrqc/1dTUlMo///zzqfyL/3fCzpo2bVoq393dncpXW/b6z+Z3h2qvqaamJpXP3kafeeaZVD57m6uvr0/ls7fR7PVD3mDuk4aGhlS+2rfHxx9/PJWvdkf0t04pgyFDUp9mmpbtrOxtOnufWbRoUSr/kY98JJUfOnRoKp/VHx+X9HeDuVMyNm/enMpnz8ctLS2pfFZHR0cqn/0M/WqfK6vd57vj3FHt6yirq6srlc8+h8i69957U/kDDzwwlf/DH/6QypOnTwambP/8+te/rtJKXrB06dKqbh9eqtqPwQaq/vWoBQAAAAAAYBcZegAAAAAAAKVg6AEAAAAAAJSCoQcAAAAAAFAKhh4AAAAAAEApGHoAAAAAAAClYOgBAAAAAACUgqEHAAAAAABQCoYeAAAAAABAKRh6AAAAAAAApWDoAQAAAAAAlEJdXy9gIBg6dGgq393dnco3NDSk8hs2bEjl29vbU/n6+vpUftu2bal8tdXU1PT1ErZTFEUqP2RI/5pHZu8D2dvc5s2bU/ns9dPR0VHV7UNG9v5UV5er6s7OzlT+pptuSuW/+MUvpvJbt25N5Wtra1P5rq6uVJ5Xlz0HZh/3ZI9ZtkOXLl2aymfvM9nHbdBftLW1pfLjx49P5VevXp3KZ2XPNdn+yW4/K/v4OGtXngNlz69Z2U7P5rOP8att/fr1qXx2fydMmJDKA8Bg5pU9AAAAAACgFAw9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKoa6vFzAQNDY2pvKdnZ2pfFNTUyq/adOmVH7btm2pfFEUqXx2f2tra1P57u7uqubr6+tT+SFD8rPC7HWa3Ye6utxdua2trarb37JlSyqfvY1WW/Y2ARkzZ85M5bPnzOw5+corr0zlL7vsslR+7dq1qXz2fJlVU1OTymfP+dnzd7X3d1dUu7M6OjpS+cmTJ6fyK1asSOWHDx+eyre2tqby2Q7N3odhZz333HOp/ObNm6u0kl2TPR9PmDAhlW9paUnls/ftasuei3eH7HWU7ej+9ph9w4YNqXz2MV5/218A6M+80wMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFKo6+sFDARdXV1VzTc1NaXyzzzzTCo/bNiwVH706NGp/LZt21L5hoaGVL6zszOVz+ro6Ejl6+vr07+jtrY2lc+uKXudZvdh6NChqXxRFKl8tY9Be3t7Kl9TU5PKQ0b2HJu9fz/22GOpfPYcnpU9/1X7/trd3Z3KDxmS+/9Dsue/bD4iv8/Z31Ht7Wev0y1btqTy2dvQ5s2bU/lsB1X7cQxUS/a+mn08l3Xsscem8l/84hdT+ex9O3uuzJ7LsueO5ubmVD4i34nZTt+4cWMqv3Xr1lQ++xyl2rfRap/vs48JAWAw804PAAAAAACgFAw9AAAAAACAUjD0AAAAAAAASsHQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKoa6vF1BGNTU1qXxjY2MqX1eXO2xr165N5UeOHJnKd3d3p/LZ9fc3tbW16Z/p7OxM5bPX6ZAhufllR0dHKj927NhUPnuMs/mmpqZUvqWlJZXPHi8GtwMPPDCVf8c73pHKb9iwIZV/8MEHU/ms9vb2VH706NFV3X72nJzt6Oz5Nasoiqpuf3fInjOz5/zm5uZUPuu//uu/Uvk///M/T+V/9KMfpfJf+MIXUvlHH300lWfw2nPPPVP57Ply3bp1qXzWI488ksp/+MMfrtJKYMc2bdqUymcfA2SfIwLAYOadHgAAAAAAQCmkhh6XXXZZHH744TFixIiYMGFCnHLKKdv932Vz5syJmpqaXl+f/OQnK7poAAY2fQJApegUACpBnwCUR2roceedd8bZZ58dS5Ysidtvvz06Ojpi3rx50dra2it35plnxrPPPtvzdfnll1d00QAMbPoEgErRKQBUgj4BKI/Uhyrfeuutvf69YMGCmDBhQtx7771xzDHH9Fze3NwckyZNqswKASgdfQJApegUACpBnwCUx2v6mx4bN26MiO3/yPF1110X48aNiwMPPDAuuOCC2LJly8tuo62tLVpaWnp9ATC4VKJPInQKAJ6jAFAZ+gRg4Eq90+NPdXd3x2c+85k46qij4sADD+y5/IMf/GBMnz49pkyZEg8++GB8/vOfj0cffTR+/OMf73A7l112WVxyySW7ugwABrhK9UmETgEY7DxHAaAS9AnAwLbLQ4+zzz47li5dGr/4xS96XX7WWWf1/PdBBx0UkydPjuOPPz6WLVsWs2bN2m47F1xwQZx33nk9/25paYlp06bt6rIAGGAq1ScROgVgsPMcBYBK0CcAA9suDT3OOeec+OlPfxp33XVXTJ069RWzs2fPjoiIxx9/fIcF0NjYGI2NjbuyDAAGuEr2SYROARjMPEcBoBL0CcDAlxp6FEURn/70p+Omm26KRYsWxYwZM171Z377299GRMTkyZN3aYEAlI8+AaBSdAoAlaBPAMojNfQ4++yz4/rrr49bbrklRowYEatWrYqIiFGjRkVTU1MsW7Ysrr/++nj7298ee+yxRzz44INx7rnnxjHHHBMHH3xwVXYAgIFHnwBQKToFgErQJwDlkRp6fPOb34yIiDlz5vS6/JprromPfvSj0dDQEP/93/8dV155ZbS2tsa0adPi3e9+d3zpS1+q2IIBGPj0CQCVolMAqAR9AlAe6Y+3eiXTpk2LO++88zUtqD/q7OxM5YcMGVKllbxg3LhxqfyLb7fcWT/60Y9S+ez1U1eX+1MyNTU1qXy1r/9Xux/sSPY6qq2tTf+OjK6urlQ+u55169al8gceeGAqn71NZD9DdVeOMTll6pP99tsvld9///1T+eztd82aNal81pgxY1L57P52d3en8lnZjsieb8ogew6s9jHLdmhWW1tbKj9s2LBU/sQTT0zlr7766lT+0UcfTeXLqEydUk3Z2259fX1V81nVfk6QfXxcbdn97Y+PX7P7UO189nloth+am5tT+ext9IADDkjlydMnAOVR3VeHAQAAAAAAdhNDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUqjr6wUMBOvXr0/lm5ubU/lnnnkmld+8eXMqn5XdX3it1qxZU9Xtb9iwIZXfuHFjdRZCKf3nf/5nKn/hhRem8qNHj07lf/SjH6XyWVu2bEnl77vvviqtBCrjyiuvTOV/97vfpfLbtm1L5R9++OFUHnbWqaeemsofccQRqfwf/vCHVD6rKIpUvqurq0or2T2y+9sfZfeh2vvc3d1d1e3/4Ac/SOXHjh2byn//+99P5QFgMPNODwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUqjr6wW8VFEUfb2E7XR3d6fyXV1dqXxnZ2dVtw/9XX+7z2Tv8/1RfzyX9oXdcT1kf0d7e3sq39bWlsqX4fYLu1O2I7L3yex9vj/eh3VKOa6D7D5kH2/1x9su/Klq3487OjpS+S1btqTy2T7pj8pwLn2tXAcAr93OnEtrin52xn366adj2rRpfb0MgAFtxYoVMXXq1L5eRp/TKQCvnU7RJwCVoE/0CUAl7Eyf9LuhR3d3d6xcuTJGjBgRNTU1PZe3tLTEtGnTYsWKFTFy5Mg+XOHuM9j22f6Wm/3dPYqiiE2bNsWUKVNiyBCfYKhTXmB/y83+lp9O6Xv65AX2t/wG2z7b391Dn/wvffK/Bts+299ys7+7R6ZP+t3HWw0ZMuQVJzUjR44cFDeePzXY9tn+lpv9rb5Ro0bt1t/Xn+mU3uxvudnf8tMpfUef9GZ/y2+w7bP9rT598gJ9sr3Bts/2t9zsb/XtbJ8M7hE7AAAAAABQGoYeAAAAAABAKQyYoUdjY2NcdNFF0djY2NdL2W0G2z7b33Kzv/Qng+342N9ys7/lNxj3eaAYbMfG/pbfYNtn+0t/MRiPzWDbZ/tbbva3/+l3f8gcAAAAAABgVwyYd3oAAAAAAAC8EkMPAAAAAACgFAw9AAAAAACAUjD0AAAAAAAASmHADD3mz58fe+21VwwdOjRmz54dv/71r/t6SVVx8cUXR01NTa+v/fffv6+XVTF33XVXvPOd74wpU6ZETU1N3Hzzzb2+XxRFfPnLX47JkydHU1NTzJ07Nx577LG+WWyFvNo+f/SjH93umJ944ol9s9jX6LLLLovDDz88RowYERMmTIhTTjklHn300V6Zbdu2xdlnnx177LFHDB8+PN797nfH6tWr+2jFr83O7O+cOXO2O76f/OQn+2jFRAyePonQKWXrlMHUJxE6RacMDIOlU/SJPtEnA4c+GZj0STkMtj6JGFydMtj6JGJgd8qAGHr84Ac/iPPOOy8uuuiiuO++++KQQw6JE044IZ577rm+XlpVvOENb4hnn3225+sXv/hFXy+pYlpbW+OQQw6J+fPn7/D7l19+eVx11VXxrW99K+6+++4YNmxYnHDCCbFt27bdvNLKebV9jog48cQTex3z73//+7txhZVz5513xtlnnx1LliyJ22+/PTo6OmLevHnR2trakzn33HPjP/7jP+LGG2+MO++8M1auXBmnnXZaH6561+3M/kZEnHnmmb2O7+WXX95HK2aw9UmETilTpwymPonQKTql/xtsnaJP9MlApU/0SX+nT/TJQO2TiMHVKYOtTyIGeKcUA8ARRxxRnH322T3/7urqKqZMmVJcdtllfbiq6rjooouKQw45pK+XsVtERHHTTTf1/Lu7u7uYNGlSccUVV/RctmHDhqKxsbH4/ve/3wcrrLyX7nNRFMUZZ5xRnHzyyX2ynmp77rnniogo7rzzzqIoXjie9fX1xY033tiT+f3vf19ERLF48eK+WmbFvHR/i6Iojj322OJv//Zv+25R9DKY+qQodEqZO2Ww9UlR6JSi0Cn9zWDqFH2iT8pEn+iT/kaflNNg65OiGHydMtj6pCgGVqf0+3d6tLe3x7333htz587tuWzIkCExd+7cWLx4cR+urHoee+yxmDJlSsycOTM+9KEPxVNPPdXXS9otnnzyyVi1alWvYz1q1KiYPXt2aY/1ixYtWhQTJkyI/fbbLz71qU/FunXr+npJFbFx48aIiBg7dmxERNx7773R0dHR6xjvv//+seeee5biGL90f1903XXXxbhx4+LAAw+MCy64ILZs2dIXyxv0BmOfROiUwdYpZe2TCJ3yIp3SPwzGTtEn+qQs9MkL9En/oE/0Sdn7JKK8nTLY+iRiYHVKXV8v4NWsXbs2urq6YuLEib0unzhxYjzyyCN9tKrqmT17dixYsCD222+/ePbZZ+OSSy6Jo48+OpYuXRojRozo6+VV1apVqyIidnisX/xeGZ144olx2mmnxYwZM2LZsmXxhS98IU466aRYvHhx1NbW9vXydll3d3d85jOfiaOOOioOPPDAiHjhGDc0NMTo0aN7ZctwjHe0vxERH/zgB2P69OkxZcqUePDBB+Pzn/98PProo/HjH/+4D1c7OA22PonQKRGDq1PK2icROuVFOqX/GGydok/0iT4ZmPRJ/6dP9EkZzjWvpKydMtj6JGLgdUq/H3oMNieddFLPfx988MExe/bsmD59etxwww3xV3/1V324Mqrl9NNP7/nvgw46KA4++OCYNWtWLFq0KI4//vg+XNlrc/bZZ8fSpUtL9fmcr+Tl9vess87q+e+DDjooJk+eHMcff3wsW7YsZs2atbuXySCjUwaXsvZJhE55kU6hr+iTwUWflIc+ob/RJ4NPWTtlsPVJxMDrlH7/8Vbjxo2L2tra7f7S/erVq2PSpEl9tKrdZ/To0bHvvvvG448/3tdLqboXj+dgPdYvmjlzZowbN25AH/NzzjknfvrTn8bChQtj6tSpPZdPmjQp2tvbY8OGDb3yA/0Yv9z+7sjs2bMjIgb08R2oBnufROiUF/89WI53GfokQqe8Ep3SdwZ7p+iTwXOsI/TJQKVPBgZ9ok8Gy7F+URk6ZbD1ScTA7JR+P/RoaGiIQw89NO64446ey7q7u+OOO+6II488sg9Xtnts3rw5li1bFpMnT+7rpVTdjBkzYtKkSb2OdUtLS9x9992D4li/6Omnn45169YNyGNeFEWcc845cdNNN8XPf/7zmDFjRq/vH3rooVFfX9/rGD/66KPx1FNPDchj/Gr7uyO//e1vIyIG5PEd6AZ7n0TolMHWKQO5TyJ0ik7p3wZ7p+gTfTKQ6BN90p/pE30ymPokYmB3ymDrk4gB3il99zfUd96///u/F42NjcWCBQuKhx9+uDjrrLOK0aNHF6tWrerrpVXc//f//X/FokWLiieffLL45S9/WcydO7cYN25c8dxzz/X10ipi06ZNxf3331/cf//9RUQUX//614v777+/+OMf/1gURVF89atfLUaPHl3ccsstxYMPPlicfPLJxYwZM4qtW7f28cp33Svt86ZNm4rPfvazxeLFi4snn3yy+O///u/iTW96U7HPPvsU27Zt6+ulp33qU58qRo0aVSxatKh49tlne762bNnSk/nkJz9Z7LnnnsXPf/7z4p577imOPPLI4sgjj+zDVe+6V9vfxx9/vLj00kuLe+65p3jyySeLW265pZg5c2ZxzDHH9PHKB6/B1CdFoVPK1imDqU+KQqfolP5vMHWKPtEn+mTg0CcDjz7RJwO1T4picHXKYOuTohjYnTIghh5FURT//M//XOy5555FQ0NDccQRRxRLlizp6yVVxfvf//5i8uTJRUNDQ/G6172ueP/73188/vjjfb2silm4cGEREdt9nXHGGUVRFEV3d3dx4YUXFhMnTiwaGxuL448/vnj00Uf7dtGv0Svt85YtW4p58+YV48ePL+rr64vp06cXZ5555oB9cLOj/YyI4pprrunJbN26tfibv/mbYsyYMUVzc3Nx6qmnFs8++2zfLfo1eLX9feqpp4pjjjmmGDt2bNHY2Fjsvffexec+97li48aNfbvwQW6w9ElR6JSydcpg6pOi0Ck6ZWAYLJ2iT/SJPhk49MnApE/KYbD1SVEMrk4ZbH1SFAO7U2qKoihe/f0gAAAAAAAA/Vu//5seAAAAAAAAO8PQAwAAAAAAKAVDDwAAAAAAoBQMPQAAAAAAgFIw9AAAAAAAAErB0AMAAAAAACgFQw8AAAAAAKAUDD0AAAAAAIBSMPQAAAAAAABKwdADAAAAAAAoBUMPAAAAAACgFAw9AAAAAACAUvj/AQq6kRxHWFSvAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","#batch_size = 8\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(128, input_shape=(784,), activation='relu'))\n","# The second dense layer\n","model.add(Dense(64, activation='relu'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"vt7glvYsBttM","executionInfo":{"status":"ok","timestamp":1708907739441,"user_tz":360,"elapsed":43155,"user":{"displayName":"U S","userId":"13531373332520883304"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2ef2bee0-efc8-4879-d27c-19b574f6dd55"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 128)               100480    \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 109386 (427.29 KB)\n","Trainable params: 109386 (427.29 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.1575 - accuracy: 0.6355\n","Epoch 2/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.6780 - accuracy: 0.7714\n","Epoch 3/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5884 - accuracy: 0.7999\n","Epoch 4/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.5418 - accuracy: 0.8146\n","Epoch 5/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.5114 - accuracy: 0.8241\n","Epoch 6/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4907 - accuracy: 0.8299\n","Epoch 7/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4753 - accuracy: 0.8351\n","Epoch 8/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4624 - accuracy: 0.8388\n","Epoch 9/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4516 - accuracy: 0.8424\n","Epoch 10/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4419 - accuracy: 0.8466\n","Epoch 11/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4344 - accuracy: 0.8490\n","Epoch 12/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4273 - accuracy: 0.8515\n","Epoch 13/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4204 - accuracy: 0.8534\n","Epoch 14/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4156 - accuracy: 0.8554\n","Epoch 15/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4100 - accuracy: 0.8572\n","Epoch 16/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4048 - accuracy: 0.8601\n","Epoch 17/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3994 - accuracy: 0.8604\n","Epoch 18/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3949 - accuracy: 0.8622\n","Epoch 19/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3902 - accuracy: 0.8641\n","Epoch 20/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3873 - accuracy: 0.8644\n","Test score: 0.433456689119339\n","Test accuracy: 0.8446999788284302\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","#batch_size = 8\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(128, input_shape=(784,), activation='tanh'))\n","# The second dense layer\n","model.add(Dense(64, activation='tanh'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heH-ET58rJBN","executionInfo":{"status":"ok","timestamp":1708907956808,"user_tz":360,"elapsed":40660,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"28547332-eb3a-4679-e6ae-c7d3add4551b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 128)               100480    \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_5 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 109386 (427.29 KB)\n","Trainable params: 109386 (427.29 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 2s 4ms/step - loss: 1.0517 - accuracy: 0.6846\n","Epoch 2/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.6587 - accuracy: 0.7869\n","Epoch 3/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5721 - accuracy: 0.8071\n","Epoch 4/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5264 - accuracy: 0.8199\n","Epoch 5/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4971 - accuracy: 0.8281\n","Epoch 6/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4765 - accuracy: 0.8330\n","Epoch 7/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4608 - accuracy: 0.8384\n","Epoch 8/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4480 - accuracy: 0.8429\n","Epoch 9/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4371 - accuracy: 0.8457\n","Epoch 10/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4282 - accuracy: 0.8495\n","Epoch 11/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4202 - accuracy: 0.8525\n","Epoch 12/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4135 - accuracy: 0.8534\n","Epoch 13/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4070 - accuracy: 0.8562\n","Epoch 14/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4017 - accuracy: 0.8567\n","Epoch 15/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3962 - accuracy: 0.8590\n","Epoch 16/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3918 - accuracy: 0.8605\n","Epoch 17/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3870 - accuracy: 0.8625\n","Epoch 18/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3833 - accuracy: 0.8641\n","Epoch 19/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3796 - accuracy: 0.8651\n","Epoch 20/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3755 - accuracy: 0.8668\n","Test score: 0.4122579097747803\n","Test accuracy: 0.8525000214576721\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","batch_size = X_train.shape[0]\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(128, input_shape=(784,), activation='sigmoid'))\n","# The second dense layer\n","model.add(Dense(64, activation='sigmoid'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tn2qbRwSyEvI","executionInfo":{"status":"ok","timestamp":1708908009622,"user_tz":360,"elapsed":16678,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"38729880-51f9-49af-cab6-310bbbda1c8b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 128)               100480    \n","                                                                 \n"," dense_7 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_8 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 109386 (427.29 KB)\n","Trainable params: 109386 (427.29 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","1/1 [==============================] - 1s 1s/step - loss: 2.4811 - accuracy: 0.0991\n","Epoch 2/20\n","1/1 [==============================] - 1s 695ms/step - loss: 2.4750 - accuracy: 0.0989\n","Epoch 3/20\n","1/1 [==============================] - 1s 696ms/step - loss: 2.4691 - accuracy: 0.0986\n","Epoch 4/20\n","1/1 [==============================] - 1s 705ms/step - loss: 2.4633 - accuracy: 0.0983\n","Epoch 5/20\n","1/1 [==============================] - 1s 716ms/step - loss: 2.4577 - accuracy: 0.0978\n","Epoch 6/20\n","1/1 [==============================] - 1s 656ms/step - loss: 2.4524 - accuracy: 0.0973\n","Epoch 7/20\n","1/1 [==============================] - 1s 678ms/step - loss: 2.4472 - accuracy: 0.0968\n","Epoch 8/20\n","1/1 [==============================] - 1s 678ms/step - loss: 2.4421 - accuracy: 0.0963\n","Epoch 9/20\n","1/1 [==============================] - 1s 658ms/step - loss: 2.4373 - accuracy: 0.0957\n","Epoch 10/20\n","1/1 [==============================] - 1s 1s/step - loss: 2.4325 - accuracy: 0.0949\n","Epoch 11/20\n","1/1 [==============================] - 1s 1s/step - loss: 2.4280 - accuracy: 0.0942\n","Epoch 12/20\n","1/1 [==============================] - 1s 1s/step - loss: 2.4236 - accuracy: 0.0934\n","Epoch 13/20\n","1/1 [==============================] - 1s 685ms/step - loss: 2.4193 - accuracy: 0.0926\n","Epoch 14/20\n","1/1 [==============================] - 1s 713ms/step - loss: 2.4152 - accuracy: 0.0917\n","Epoch 15/20\n","1/1 [==============================] - 1s 661ms/step - loss: 2.4112 - accuracy: 0.0911\n","Epoch 16/20\n","1/1 [==============================] - 1s 684ms/step - loss: 2.4073 - accuracy: 0.0904\n","Epoch 17/20\n","1/1 [==============================] - 1s 679ms/step - loss: 2.4036 - accuracy: 0.0899\n","Epoch 18/20\n","1/1 [==============================] - 1s 592ms/step - loss: 2.4000 - accuracy: 0.0891\n","Epoch 19/20\n","1/1 [==============================] - 1s 599ms/step - loss: 2.3965 - accuracy: 0.0883\n","Epoch 20/20\n","1/1 [==============================] - 1s 576ms/step - loss: 2.3931 - accuracy: 0.0878\n","Test score: 2.3897011280059814\n","Test accuracy: 0.08669999986886978\n"]}]},{"cell_type":"markdown","source":["In this task, you'll implement several ANN models with different learning rates for the stochastic gradient descent. In all of the models below, use 128 as your mini-batch size.\n","\n","Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use 0.01 as the learning rate.\n","Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use 100 as the learning rate.\n","Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use 0.0000001 as the learning rate.\n","Compare the results of each model. Which learning rate performed best?"],"metadata":{"id":"MwOb_x0etjEa"}},{"cell_type":"code","source":["from tensorflow.keras import optimizers\n","sgd_001 = optimizers.SGD(lr=0.01)\n","sgd_100 = optimizers.SGD(lr=100)\n","sgd_00000001 = optimizers.SGD(lr=0.0000001)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YVXxuacAtlp4","executionInfo":{"status":"ok","timestamp":1708905620321,"user_tz":360,"elapsed":203,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"b956b79b-49e9-408c-e4f9-ce87b1f793fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n","WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n","WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","#batch_size = 128\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(784, input_shape=(784,), activation='relu'))\n","# The second dense layer\n","model.add(Dense(256, activation='relu'))\n","# The third dense layer\n","model.add(Dense(128, input_shape=(784,), activation='relu'))\n","# The fourth dense layer\n","model.add(Dense(64, activation='relu'))\n","# The fourth dense layer\n","model.add(Dense(32, activation='relu'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rksuG1ZuyE7v","executionInfo":{"status":"ok","timestamp":1708908337440,"user_tz":360,"elapsed":204273,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"42e915bd-f5bd-46fe-d29a-e20f03456c5c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_21 (Dense)            (None, 784)               615440    \n","                                                                 \n"," dense_22 (Dense)            (None, 256)               200960    \n","                                                                 \n"," dense_23 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_24 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_25 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dense_26 (Dense)            (None, 10)                330       \n","                                                                 \n","=================================================================\n","Total params: 859962 (3.28 MB)\n","Trainable params: 859962 (3.28 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 7s 15ms/step - loss: 1.2884 - accuracy: 0.5846\n","Epoch 2/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.5952 - accuracy: 0.7918\n","Epoch 3/20\n","469/469 [==============================] - 8s 16ms/step - loss: 0.5095 - accuracy: 0.8208\n","Epoch 4/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.4698 - accuracy: 0.8356\n","Epoch 5/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.4444 - accuracy: 0.8440\n","Epoch 6/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.4241 - accuracy: 0.8504\n","Epoch 7/20\n","469/469 [==============================] - 9s 18ms/step - loss: 0.4070 - accuracy: 0.8565\n","Epoch 8/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.3977 - accuracy: 0.8597\n","Epoch 9/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.3811 - accuracy: 0.8652\n","Epoch 10/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.3729 - accuracy: 0.8685\n","Epoch 11/20\n","469/469 [==============================] - 7s 14ms/step - loss: 0.3618 - accuracy: 0.8737\n","Epoch 12/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.3538 - accuracy: 0.8742\n","Epoch 13/20\n","469/469 [==============================] - 7s 14ms/step - loss: 0.3464 - accuracy: 0.8783\n","Epoch 14/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.3385 - accuracy: 0.8806\n","Epoch 15/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.3324 - accuracy: 0.8805\n","Epoch 16/20\n","469/469 [==============================] - 8s 16ms/step - loss: 0.3242 - accuracy: 0.8853\n","Epoch 17/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.3181 - accuracy: 0.8865\n","Epoch 18/20\n","469/469 [==============================] - 7s 14ms/step - loss: 0.3127 - accuracy: 0.8883\n","Epoch 19/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.3048 - accuracy: 0.8912\n","Epoch 20/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.2999 - accuracy: 0.8927\n","Test score: 0.3789913058280945\n","Test accuracy: 0.8633000254631042\n"]}]},{"cell_type":"code","source":["# different number of layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","#batch_size = 128\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(784, input_shape=(784,), activation='relu'))\n","# The second dense layer\n","model.add(Dense(256, activation='relu'))\n","# The third dense layer\n","model.add(Dense(128, input_shape=(784,), activation='relu'))\n","# The fourth dense layer\n","model.add(Dense(64, activation='relu'))\n","# The fourth dense layer\n","model.add(Dense(32, activation='relu'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOcfLHrF4UuJ","executionInfo":{"status":"ok","timestamp":1708908655321,"user_tz":360,"elapsed":204943,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"1afe9507-c179-458b-814e-4c71c2efabbf"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_27 (Dense)            (None, 784)               615440    \n","                                                                 \n"," dense_28 (Dense)            (None, 256)               200960    \n","                                                                 \n"," dense_29 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_30 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_31 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dense_32 (Dense)            (None, 10)                330       \n","                                                                 \n","=================================================================\n","Total params: 859962 (3.28 MB)\n","Trainable params: 859962 (3.28 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 8s 15ms/step - loss: 1.0028 - accuracy: 0.4143\n","Epoch 2/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.9752 - accuracy: 0.5799\n","Epoch 3/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.8267 - accuracy: 0.6053\n","Epoch 4/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.6537 - accuracy: 0.6771\n","Epoch 5/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.5374 - accuracy: 0.7533\n","Epoch 6/20\n","469/469 [==============================] - 7s 14ms/step - loss: 0.4524 - accuracy: 0.7951\n","Epoch 7/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.4047 - accuracy: 0.8131\n","Epoch 8/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.3763 - accuracy: 0.8220\n","Epoch 9/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.3552 - accuracy: 0.8310\n","Epoch 10/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.3421 - accuracy: 0.8353\n","Epoch 11/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.3308 - accuracy: 0.8401\n","Epoch 12/20\n","469/469 [==============================] - 9s 19ms/step - loss: 0.3226 - accuracy: 0.8437\n","Epoch 13/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.3145 - accuracy: 0.8483\n","Epoch 14/20\n","469/469 [==============================] - 8s 18ms/step - loss: 0.3069 - accuracy: 0.8509\n","Epoch 15/20\n","469/469 [==============================] - 13s 28ms/step - loss: 0.3004 - accuracy: 0.8539\n","Epoch 16/20\n","469/469 [==============================] - 10s 22ms/step - loss: 0.2964 - accuracy: 0.8557\n","Epoch 17/20\n","469/469 [==============================] - 7s 14ms/step - loss: 0.2925 - accuracy: 0.8569\n","Epoch 18/20\n","469/469 [==============================] - 8s 17ms/step - loss: 0.2866 - accuracy: 0.8607\n","Epoch 19/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.2824 - accuracy: 0.8620\n","Epoch 20/20\n","469/469 [==============================] - 8s 16ms/step - loss: 0.2796 - accuracy: 0.8633\n","Test score: 0.3147358298301697\n","Test accuracy: 0.843500018119812\n"]}]},{"cell_type":"code","source":["# different activation function\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","#batch_size = 128\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(128, input_shape=(784,), activation='relu'))\n","# The second dense layer\n","model.add(Dense(64, activation='relu'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0U-iRlVI4yr3","executionInfo":{"status":"ok","timestamp":1708909053676,"user_tz":360,"elapsed":83786,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"f80413d7-fb1b-4e8c-96c3-4d75655d729c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_42 (Dense)            (None, 128)               100480    \n","                                                                 \n"," dense_43 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_44 (Dense)            (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 109386 (427.29 KB)\n","Trainable params: 109386 (427.29 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9959 - accuracy: 0.4001\n","Epoch 2/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.8745 - accuracy: 0.5568\n","Epoch 3/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.7076 - accuracy: 0.6546\n","Epoch 4/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6206 - accuracy: 0.6865\n","Epoch 5/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5739 - accuracy: 0.7168\n","Epoch 6/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.5361 - accuracy: 0.7545\n","Epoch 7/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4991 - accuracy: 0.7822\n","Epoch 8/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4649 - accuracy: 0.7992\n","Epoch 9/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4372 - accuracy: 0.8100\n","Epoch 10/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4158 - accuracy: 0.8163\n","Epoch 11/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3991 - accuracy: 0.8216\n","Epoch 12/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3861 - accuracy: 0.8253\n","Epoch 13/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3751 - accuracy: 0.8286\n","Epoch 14/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3663 - accuracy: 0.8320\n","Epoch 15/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3587 - accuracy: 0.8351\n","Epoch 16/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3517 - accuracy: 0.8374\n","Epoch 17/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3456 - accuracy: 0.8393\n","Epoch 18/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3406 - accuracy: 0.8421\n","Epoch 19/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3357 - accuracy: 0.8435\n","Epoch 20/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3313 - accuracy: 0.8452\n","Test score: 0.3520042896270752\n","Test accuracy: 0.8334000110626221\n"]}]},{"cell_type":"code","source":["# different activation function\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","#batch_size = 128\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(128, input_shape=(784,), activation='tanh'))\n","# The second dense layer\n","model.add(Dense(64, activation='tanh'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FexXz1yb6m3P","executionInfo":{"status":"ok","timestamp":1708909102686,"user_tz":360,"elapsed":42699,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"4d2be31d-5d13-4835-efce-dad426ba9122"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_45 (Dense)            (None, 128)               100480    \n","                                                                 \n"," dense_46 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_47 (Dense)            (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 109386 (427.29 KB)\n","Trainable params: 109386 (427.29 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.9573 - accuracy: 0.4864\n","Epoch 2/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.7516 - accuracy: 0.6589\n","Epoch 3/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.6344 - accuracy: 0.7168\n","Epoch 4/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5615 - accuracy: 0.7525\n","Epoch 5/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5119 - accuracy: 0.7718\n","Epoch 6/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4787 - accuracy: 0.7875\n","Epoch 7/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4537 - accuracy: 0.8006\n","Epoch 8/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4338 - accuracy: 0.8085\n","Epoch 9/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4172 - accuracy: 0.8142\n","Epoch 10/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4040 - accuracy: 0.8181\n","Epoch 11/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3930 - accuracy: 0.8220\n","Epoch 12/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3837 - accuracy: 0.8251\n","Epoch 13/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3759 - accuracy: 0.8274\n","Epoch 14/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3690 - accuracy: 0.8301\n","Epoch 15/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3629 - accuracy: 0.8321\n","Epoch 16/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3573 - accuracy: 0.8347\n","Epoch 17/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8365\n","Epoch 18/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3478 - accuracy: 0.8388\n","Epoch 19/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3435 - accuracy: 0.8403\n","Epoch 20/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3399 - accuracy: 0.8418\n","Test score: 0.3585107624530792\n","Test accuracy: 0.8294000029563904\n"]}]},{"cell_type":"code","source":["# different activation function\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","#batch_size = 128\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(128, input_shape=(784,), activation='sigmoid'))\n","# The second dense layer\n","model.add(Dense(64, activation='sigmoid'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9vzj0AL6o-L","executionInfo":{"status":"ok","timestamp":1708909191754,"user_tz":360,"elapsed":83813,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"49d8b428-492c-4d0e-b07e-15b1284524ff"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_48 (Dense)            (None, 128)               100480    \n","                                                                 \n"," dense_49 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_50 (Dense)            (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 109386 (427.29 KB)\n","Trainable params: 109386 (427.29 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 2s 4ms/step - loss: 1.0256 - accuracy: 0.1039\n","Epoch 2/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.0092 - accuracy: 0.2340\n","Epoch 3/20\n","469/469 [==============================] - 2s 4ms/step - loss: 1.0049 - accuracy: 0.3340\n","Epoch 4/20\n","469/469 [==============================] - 2s 4ms/step - loss: 1.0010 - accuracy: 0.4043\n","Epoch 5/20\n","469/469 [==============================] - 2s 4ms/step - loss: 1.0004 - accuracy: 0.4471\n","Epoch 6/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9999 - accuracy: 0.4783\n","Epoch 7/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9994 - accuracy: 0.5003\n","Epoch 8/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.9990 - accuracy: 0.5194\n","Epoch 9/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9986 - accuracy: 0.5357\n","Epoch 10/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9982 - accuracy: 0.5502\n","Epoch 11/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9978 - accuracy: 0.5630\n","Epoch 12/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9975 - accuracy: 0.5747\n","Epoch 13/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.9971 - accuracy: 0.5831\n","Epoch 14/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.9967 - accuracy: 0.5916\n","Epoch 15/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.9964 - accuracy: 0.5972\n","Epoch 16/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9960 - accuracy: 0.6026\n","Epoch 17/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9956 - accuracy: 0.6082\n","Epoch 18/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9951 - accuracy: 0.6123\n","Epoch 19/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9947 - accuracy: 0.6161\n","Epoch 20/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.9943 - accuracy: 0.6182\n","Test score: 0.9941178560256958\n","Test accuracy: 0.6136000156402588\n"]}]},{"cell_type":"code","source":["# different batch size\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","batch_size = 64\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(128, input_shape=(784,), activation='relu'))\n","# The second dense layer\n","model.add(Dense(64, activation='relu'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wxAULwg6HjE","executionInfo":{"status":"ok","timestamp":1708909282228,"user_tz":360,"elapsed":83783,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"a45180cf-b318-433e-fd86-ab359506b240"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_51 (Dense)            (None, 128)               100480    \n","                                                                 \n"," dense_52 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_53 (Dense)            (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 109386 (427.29 KB)\n","Trainable params: 109386 (427.29 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","938/938 [==============================] - 4s 3ms/step - loss: 0.9389 - accuracy: 0.4882\n","Epoch 2/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.6555 - accuracy: 0.6825\n","Epoch 3/20\n","938/938 [==============================] - 4s 4ms/step - loss: 0.5431 - accuracy: 0.7594\n","Epoch 4/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.4644 - accuracy: 0.7996\n","Epoch 5/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.4155 - accuracy: 0.8143\n","Epoch 6/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.3874 - accuracy: 0.8236\n","Epoch 7/20\n","938/938 [==============================] - 4s 5ms/step - loss: 0.3686 - accuracy: 0.8305\n","Epoch 8/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.3549 - accuracy: 0.8342\n","Epoch 9/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.3445 - accuracy: 0.8387\n","Epoch 10/20\n","938/938 [==============================] - 4s 4ms/step - loss: 0.3356 - accuracy: 0.8424\n","Epoch 11/20\n","938/938 [==============================] - 4s 4ms/step - loss: 0.3284 - accuracy: 0.8448\n","Epoch 12/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.3216 - accuracy: 0.8486\n","Epoch 13/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.3161 - accuracy: 0.8504\n","Epoch 14/20\n","938/938 [==============================] - 4s 4ms/step - loss: 0.3109 - accuracy: 0.8525\n","Epoch 15/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.3062 - accuracy: 0.8545\n","Epoch 16/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.3024 - accuracy: 0.8561\n","Epoch 17/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.2983 - accuracy: 0.8580\n","Epoch 18/20\n","938/938 [==============================] - 4s 4ms/step - loss: 0.2947 - accuracy: 0.8598\n","Epoch 19/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.2919 - accuracy: 0.8599\n","Epoch 20/20\n","938/938 [==============================] - 3s 3ms/step - loss: 0.2888 - accuracy: 0.8618\n","Test score: 0.31833505630493164\n","Test accuracy: 0.8443999886512756\n"]}]},{"cell_type":"code","source":["# different batch size\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation, Dense\n","from keras import backend as K\n","from tensorflow.keras import losses\n","\n","batch_size = 128\n","\n","model = Sequential()\n","# The first dense layer\n","model.add(Dense(128, input_shape=(784,), activation='relu'))\n","# The second dense layer\n","model.add(Dense(64, activation='relu'))\n","# The last layer is the output layer\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# Setting `verbose=1` prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n","\n","score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ye_st3YZ6H7k","executionInfo":{"status":"ok","timestamp":1708909331592,"user_tz":360,"elapsed":42926,"user":{"displayName":"U S","userId":"13531373332520883304"}},"outputId":"c8f73f24-34b3-43a7-82d0-6973aa5a0281"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_14\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_54 (Dense)            (None, 128)               100480    \n","                                                                 \n"," dense_55 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dense_56 (Dense)            (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 109386 (427.29 KB)\n","Trainable params: 109386 (427.29 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.9911 - accuracy: 0.4117\n","Epoch 2/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.8455 - accuracy: 0.5697\n","Epoch 3/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.7062 - accuracy: 0.6548\n","Epoch 4/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.6149 - accuracy: 0.7064\n","Epoch 5/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5544 - accuracy: 0.7489\n","Epoch 6/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5061 - accuracy: 0.7749\n","Epoch 7/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4710 - accuracy: 0.7912\n","Epoch 8/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4451 - accuracy: 0.8008\n","Epoch 9/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4248 - accuracy: 0.8079\n","Epoch 10/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.4088 - accuracy: 0.8134\n","Epoch 11/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3953 - accuracy: 0.8180\n","Epoch 12/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3837 - accuracy: 0.8228\n","Epoch 13/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3746 - accuracy: 0.8268\n","Epoch 14/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3660 - accuracy: 0.8305\n","Epoch 15/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3590 - accuracy: 0.8331\n","Epoch 16/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3525 - accuracy: 0.8356\n","Epoch 17/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3469 - accuracy: 0.8382\n","Epoch 18/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3414 - accuracy: 0.8407\n","Epoch 19/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3370 - accuracy: 0.8418\n","Epoch 20/20\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3329 - accuracy: 0.8438\n","Test score: 0.35268673300743103\n","Test accuracy: 0.8317999839782715\n"]}]}]}